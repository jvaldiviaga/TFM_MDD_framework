#!/usr/bin/env python3
# ============================================================
# Script: qc_meg_raw.py
#
# OBJETIVO:
# Evaluar la calidad t√©cnica de los datos MEG crudos (.fif),
# detectando autom√°ticamente los problemas m√°s comunes en
# sistemas Elekta Neuromag (como los del dataset AIM/Reward).
# Este control de calidad inicial es clave para tomar decisiones
# t√©cnicas personalizadas por sujeto en el preprocesamiento posterior.
# ============================================================

# === FUNCIONES IMPLEMENTADAS ===
# ‚úÖ Interferencia 60‚ÄØHz (detecci√≥n de pico en PSD multicanal)
# ‚úÖ Ruido muscular (>50‚ÄØHz)
# ‚úÖ Drift <1‚ÄØHz (aumento de energ√≠a en baja frecuencia)
# ‚úÖ Clipping o saturaci√≥n (valores extremos en canales MEG)
# ‚úÖ Canales malos (detecci√≥n mediante Maxwell filtering)
# ‚úÖ Presencia y n√∫mero de eventos en canal STI014 (est√≠mulos)
#
# üìù Resultados exportados a:
#    - qc_psd_summary.csv        ‚Üí detecci√≥n binaria de anomal√≠as t√©cnicas
#    - qc_bad_channels.csv       ‚Üí lista de canales ruidosos o planos
#    - qc_event_check.csv        ‚Üí presencia y cantidad de eventos codificados
#    - qc_interpretation.csv     ‚Üí resumen t√©cnico-cl√≠nico interpretable por sujeto
#    - qc_ready_flag.csv         ‚Üí flag para saber si requiere preprocesamiento
#    - qc_quality_label.csv      ‚Üí clasificaci√≥n global de calidad t√©cnica
#    - *_peaks_debug.png         ‚Üí curva espectral invertida con picos detectados
#    - *_psd.png                 ‚Üí densidad espectral de potencia multicanal (0‚Äì60‚ÄØHz)

# === FUNCIONES NO INCLUIDAS (por decisi√≥n metodol√≥gica) ===
# ‚ö†Ô∏è Visualizaci√≥n espectral ya implementada (0‚Äì60‚ÄØHz completa mediante PSD multicanal).
# ‚ùå No se realiza a√∫n cuantificaci√≥n autom√°tica por bandas cognitivas espec√≠ficas
#    (e.g., alpha: 8‚Äì13‚ÄØHz, theta: 4‚Äì7‚ÄØHz, beta: 13‚Äì30‚ÄØHz).
#    Aunque dichas bandas est√°n contenidas visualmente en la PSD,
#    su an√°lisis cuantitativo requiere:
#    - segmentaci√≥n del raw en condiciones homog√©neas (epocas),
#    - eliminaci√≥n de artefactos fisiol√≥gicos (ICA: EOG, ECG),
#    - y un dise√±o experimental controlado (reposo vs tarea).
#    De lo contrario, se generar√≠an falsos positivos o medidas err√≥neas.
#    Por esta raz√≥n, la cuantificaci√≥n de bandas cognitivas se pospone
#    a fases posteriores del pipeline, como el epocado o an√°lisis de fuente.

# ‚ùå Artefactos fisiol√≥gicos (EOG, ECG) ‚Üí se detectar√°n tras filtrado e ICA
# ‚ùå Movimiento de cabeza (HPI/head_pos) ‚Üí se analizar√° solo si existe dev_head_t
# ============================================================

# ========================== LIBRER√çAS ==========================
import os                                # Para manipulaci√≥n de rutas y archivos
import argparse                          # Para lectura de argumentos desde consola
import mne                               # Para carga y procesamiento de archivos MEG (.fif)
import numpy as np                       # Para c√°lculos num√©ricos y manejo de arrays
import pandas as pd                      # Para cargar y guardar tablas (.csv)
import matplotlib                        # Backend gr√°fico para evitar errores sin GUI
matplotlib.use('Agg')                    # Forzamos backend no interactivo (por seguridad en WSL2)
import matplotlib.pyplot as plt          # Para generaci√≥n de figuras (PSD, curvas, etc.)
import seaborn as sns                    # Para visualizaci√≥n avanzada (e.g., heatmaps)
from PIL import Image                    # Para an√°lisis espectral desde la imagen PSD
from scipy.signal import find_peaks      # Para detectar picos en el perfil espectral

# ========================== PAR√ÅMETROS DE ENTRADA ==========================
# Se definen los argumentos que se deben pasar desde la terminal al ejecutar el script

parser = argparse.ArgumentParser(description="Evaluaci√≥n autom√°tica de calidad MEG crudo.")
parser.add_argument('--input_file', type=str, required=True,
                    help='Archivo .fif MEG crudo (ej. sub-XXX_meg.fif)')
parser.add_argument('--output_dir', type=str, required=True,
                    help='Directorio para guardar gr√°ficos e informes')
args = parser.parse_args()

# ========================== RUTAS Y VARIABLES CLAVE ==========================
# Expandimos rutas con ~, creamos carpeta de salida si no existe, y extraemos el ID del sujeto

input_path = os.path.expanduser(args.input_file)
output_dir = os.path.expanduser(args.output_dir)
os.makedirs(output_dir, exist_ok=True)

subject_id = os.path.basename(input_path).split("_")[0]
# ‚û§ Extraemos el ID antes del primer guion bajo (ej. sub-M87139247)

# ========================== COMPROBACI√ìN DE QC COMPLETO ==========================
# Verificamos si el QC ya fue realizado completamente (PSD + CSVs)

def check_qc_complete(output_dir, subject_id):
    psd_img = os.path.join(output_dir, f"{subject_id}_psd.png")
    summary_csv = os.path.join(output_dir, "qc_psd_summary.csv")
    bads_csv = os.path.join(output_dir, "qc_bad_channels.csv")

    # ‚û§ Si falta alguno de los tres componentes esenciales, el QC no est√° completo
    if not (os.path.exists(psd_img) and os.path.exists(summary_csv) and os.path.exists(bads_csv)):
        return False

    try:
        summary_df = pd.read_csv(summary_csv)
        bads_df = pd.read_csv(bads_csv)
        return subject_id in summary_df["subject"].values and subject_id in bads_df["subject"].values
    except Exception:
        return False  # En caso de error leyendo los CSVs, consideramos el QC incompleto

# Si el QC ya est√° completamente hecho, se omite
if check_qc_complete(output_dir, subject_id):
    print(f"‚è© QC ya completado previamente para {subject_id}. Se omite ejecuci√≥n.")
    exit(0)

# ========================== FASE 1: CARGA DEL RAW ==========================
# Intentamos cargar el archivo .fif crudo completo. Si est√° corrupto o incompleto, se registra error.
# Recorte por eficiencia computacional y justificaci√≥n cient√≠fica
# 600‚ÄØs (10‚ÄØmin) son suficientes para evaluar:
# - Pico a 60‚ÄØHz (interferencia)
# - Ruido muscular (>50‚ÄØHz)
# - Drift (<1‚ÄØHz)
# - Clipping y canales malos
#
# Umbral emp√≠ricamente validado: >600s causa errores de RAM en WSL2 al hacer raw.load_data()
# Adem√°s, los estudios de calidad MEG (H√§m√§l√§inen 2010, Gross 2013) confirman que 2‚Äì5‚ÄØmin bastan.


print(f"üìÇ Cargando archivo crudo: {input_path}")
try:
    # Cargamos el raw sin preload inicial
    raw = mne.io.read_raw_fif(input_path, preload=False)
    duration_sec = raw.n_times / raw.info["sfreq"]

    # Si la duraci√≥n es muy alta, recortamos autom√°ticamente a 600s
    if duration_sec > 600:
        raw.crop(tmax=600)
        print(f"‚ö†Ô∏è Duraci√≥n larga: {duration_sec:.1f}s ‚Üí 600s suficientes para QC t√©cnico")
    else:
        print(f"üïí Duraci√≥n: {duration_sec:.1f}s ‚Üí sin recorte necesario")

    # Cargamos los datos ya recortados (si se aplic√≥ crop) o completos
    raw.load_data()

except Exception as e:
    print(f"‚ùå ERROR: No se pudo cargar {subject_id}. Split roto o archivo corrupto: {e}")
    with open(os.path.join(output_dir, "qc_failed_subjects.txt"), "a") as f:
        f.write(f"{subject_id},{str(e)}\n")
    exit(1)


# ========================== FASE 2: DENSIDAD ESPECTRAL DE POTENCIA (PSD MULTICANAL) ==========================
 # Esta fase genera una visualizaci√≥n clave para la detecci√≥n autom√°tica y visual de artefactos espectrales.
# Detecta:
# - Pico de interferencia de red (‚ö° 60‚ÄØHz en EE.UU. / 50‚ÄØHz en Europa)
# - Ruido muscular (>50‚ÄØHz), que aparece como picos m√∫ltiples y dispersos
# - Drift excesivo (<1‚ÄØHz) como incremento de potencia en bajas frecuencias
# - Canales con distribuci√≥n espectral an√≥mala o plano (curvas atenuadas o distorsionadas)
#
# ‚ö†Ô∏è En este proyecto usamos fmax=65‚ÄØHz porque los datos proceden del estudio AIM/Reward (EE.UU.),
# donde la frecuencia de red es 60‚ÄØHz. Si se trabaja con datasets europeos, considerar fmax=50‚ÄØHz.
#
# Esta versi√≥n del PSD:
# Muestra cada canal por separado (curvas de colores) ‚Üí mejor para inspecci√≥n t√©cnica
# Guarda la imagen como PNG (no se abre ventana Qt)
# Se reutiliza despu√©s para extraer m√©tricas autom√°ticas
# Evita errores t√≠picos de entornos sin GUI (como WSL2) al usar un backend no interactivo

# Forzamos backend no interactivo (por seguridad en WSL2)
# Importamos la librer√≠a base de gr√°ficos matplotlib,
# que MNE utiliza por debajo para generar figuras.


# Mostramos por consola que inicia la generaci√≥n de la gr√°fica
print("üìà Generando PSD multicanal (curvas individuales por canal)...")

# Generamos la figura del PSD multicanal
# - fmax=65 limita el eje X a 65‚ÄØHz, suficiente para inspecci√≥n funcional y artefactos comunes
# - average=False dibuja cada canal por separado para identificar outliers
# - show=False evita mostrar la figura en pantalla (ideal para WSL2 o ejecuci√≥n por lotes)
fig_psd = raw.plot_psd(
    fmax=65,
    average=False,
    show=False
)

# Definimos el path donde se guardar√° la imagen del PSD
psd_img_path = os.path.join(output_dir, f"{subject_id}_psd.png")

# Guardamos la figura como imagen PNG
fig_psd.savefig(psd_img_path, dpi=150)  # 150 dpi ‚Üí buena resoluci√≥n sin generar archivos pesados
plt.close(fig_psd)                      # Cerramos la figura para liberar memoria

# Confirmamos por consola que la imagen se gener√≥ correctamente
print(f"‚úÖ PSD multicanal guardado como imagen: {psd_img_path}")

# === OPCIONAL: Visualizaci√≥n interactiva (desactivada por defecto) ===
# Este bloque est√° pensado para futuras interfaces gr√°ficas (e.g. Shiny, Jupyter, Qt):
# Permitir√≠a explorar la se√±al cruda antes del preprocesamiento, pero est√° desactivado
# porque puede lanzar errores en servidores o entornos sin GUI (como WSL2).
#
# try:
#     print("üß† Mostrando se√±al cruda en visor interactivo (solo en entornos gr√°ficos)...")
#     raw.plot(n_channels=50, duration=5.0, show=True)
#     print("‚úÖ Visualizaci√≥n interactiva abierta.")
# except Exception as e:
#     print(f"‚ö†Ô∏è Visualizaci√≥n interactiva no disponible: {e}")


# ========================== FASE 3: AN√ÅLISIS ESPECTRAL AUTOM√ÅTICO DESDE IMAGEN PSD ==========================
# Este enfoque evita errores comunes de MNE con compute_psd(), y es m√°s estable cl√≠nicamente.
# Analiza la imagen PNG generada en la fase anterior para detectar artefactos mediante perfil espectral invertido.

print("üî¨ Evaluando artefactos espectrales mediante an√°lisis de imagen PSD...")

# Abrimos la imagen PSD y la convertimos a escala de grises
img = Image.open(psd_img_path).convert('L')     # L = 8-bit grayscale
arr = np.array(img)                             # Convertimos la imagen a array numpy

# Extraemos una regi√≥n espectral relevante (estimada de pruebas previas)
region = arr[150:350, 200:800]

# Calculamos el perfil espectral invertido (energ√≠a relativa por frecuencia)
profile = (region.max() - region.mean(axis=0))

# Umbral adaptativo para detecci√≥n de picos
adaptive_threshold = max(10, np.percentile(profile, 90) * 0.1)

# Detectamos picos prominentes
peaks, _ = find_peaks(profile, prominence=adaptive_threshold)

# Mapeamos las posiciones de los picos a frecuencias reales (aprox. 0‚Äì60 Hz)
freq_max = 60
peak_freqs = [round(freq_max * i / (len(profile) - 1), 1) for i in peaks]

# === DIAGN√ìSTICO DE ARTEFACTOS ===
drift_present = profile[:20].mean() > profile[20:40].mean() + 2
muscle_present = any(52 <= f <= 60 for f in peak_freqs)

# === GUARDADO DE CURVA DE DEPURACI√ìN ===
debug_plot = os.path.join(output_dir, f"{subject_id}_peaks_debug.png")
plt.figure(figsize=(10, 3))
plt.plot(profile, label="Perfil espectral invertido")
plt.plot(peaks, profile[peaks], "rx", label="Picos detectados")
plt.title(f"Curva espectral invertida: {subject_id}")
plt.xlabel("Frecuencia estimada (Hz)")
plt.ylabel("Contraste")
plt.legend()
plt.tight_layout()
plt.savefig(debug_plot)
plt.close()
print(f"üìä Curva de depuraci√≥n guardada: {debug_plot}")

# === M√©tricas sint√©ticas para CSV (comparaci√≥n pre/post) ===
power_drift = float(profile[:20].mean()) if drift_present else np.nan
power_muscle = float(profile[60:].mean()) if muscle_present else np.nan
psd_mean = profile  # Para mantener compatibilidad con exportaci√≥n posterior



# ========================== FASE 4: DETECCI√ìN DE CLIPPING O SATURACI√ìN ==========================
# Aqu√≠ se eval√∫an valores extremos en la se√±al, que podr√≠an indicar clipping (saturaci√≥n).
# Este artefacto puede deberse a:
# - movimiento s√∫bito de la cabeza,
# - interferencia externa intensa,
# - errores de adquisici√≥n (amplificadores).

# Se considera que hay clipping si alg√∫n valor en los canales MEG supera los 5e-11 Tesla (50.000 fT).
# Este umbral es conservador y se basa en estudios previos y en valores observados en el dataset AIM.
print("ü©ª Evaluando saturaci√≥n de la se√±al (clipping)...")

# Primero seleccionamos solo los canales MEG (magnet√≥metros + gradiometers)
meg_data = raw.copy().pick_types(meg=True)

# Extraemos la matriz de datos MEG (canales x tiempo)
meg_values = meg_data.get_data()

# Evaluamos si existe al menos un valor fuera del umbral
has_clipping = np.any(np.abs(meg_values) > 5e-11)


# ========================== FASE 5: DETECCI√ìN DE CANALES MALOS ==========================
# Esta fase detecta canales ruidosos o planos utilizando Maxwell filtering (Elekta Neuromag).
# Esta t√©cnica permite identificar sensores defectuosos (ruido excesivo o actividad plana) para excluirlos antes del preprocesamiento.

print("üîç Detectando canales malos con Maxwell filtering (requiere archivos de calibraci√≥n y crosstalk)...")

# Rutas absolutas a los archivos de calibraci√≥n necesarios
cal_path = os.path.expanduser("~/TFM_MDD/data/neuroimaging/Code/sss_cal_3046_2009-04-29.dat")
ct_path  = os.path.expanduser("~/TFM_MDD/data/neuroimaging/Code/ct_sparse_orion.fif")

try:
    if os.path.exists(cal_path) and os.path.exists(ct_path):
        # Detecci√≥n autom√°tica de canales ruidosos y planos mediante Maxwell filtering
        bads_detected, flats_detected, scores = mne.preprocessing.find_bad_channels_maxwell(
            raw,
            calibration=cal_path,
            cross_talk=ct_path,
            return_scores=True,
            verbose='WARNING'
        )

        # Visualizaci√≥n opcional: heatmap con puntuaci√≥n de ruido por canal
        import matplotlib.pyplot as plt
        import seaborn as sns

        sns.heatmap(scores['scores_noisy'], cmap='viridis')
        plt.title(f"Canales ruidosos - {subject_id}")
        heatmap_path = os.path.join(output_dir, f"{subject_id}_bad_channel_scores.png")
        plt.savefig(heatmap_path)
        plt.close()
        print(f"üßæ Heatmap de canales ruidosos guardado: {heatmap_path}")

    else:
        print("‚ö†Ô∏è Archivos de calibraci√≥n o crosstalk no encontrados. Se omite Maxwell filtering.")
        bads_detected, flats_detected = [], []

except Exception as e:
    print(f"‚ö†Ô∏è Maxwell filtering fall√≥ por error interno: {e}")
    bads_detected, flats_detected = [], []

# A√±adir los canales malos al objeto raw.info['bads'] para su exclusi√≥n posterior
raw.info['bads'] = bads_detected

# === Exportar resultados t√©cnicos ===
# Este CSV resume los canales ruidosos y planos detectados por sujeto.
bads_out_path = os.path.join(output_dir, "qc_bad_channels.csv")

bads_df = pd.DataFrame([{
    "subject": subject_id,
    "bad_channels": ",".join(bads_detected) if bads_detected else "",
    "flat_channels": ",".join(flats_detected) if flats_detected else "",
    "n_bad": len(bads_detected),
    "n_flat": len(flats_detected)
}])

if os.path.exists(bads_out_path):
    df_old = pd.read_csv(bads_out_path)
    df_old = df_old[df_old["subject"].astype(str).str.strip().str.lower() != subject_id.strip().lower()]
else:
    df_old = pd.DataFrame()

df_final = pd.concat([df_old, bads_df], ignore_index=True)
df_final.to_csv(bads_out_path, index=False)

# Diagn√≥stico por consola
print(f"üìâ Canales malos detectados: {bads_detected if bads_detected else 'ninguno'}")


# ========================== FASE 6: VERIFICACI√ìN DEL CANAL DE EVENTOS ==========================
# En esta fase se comprueba la presencia del canal STI014, est√°ndar en BIDS-MEG para codificaci√≥n de eventos.
# Este canal es necesario para segmentar los datos en √©pocas (epoching) y detectar respuestas evocados (ERPs/ERFs).
# Si el canal existe y contiene eventos v√°lidos, se considera el sujeto apto para segmentaci√≥n.
print("üîé Verificando canal de eventos (STI014)...")

events_ok = True  # Por defecto lo asumimos como v√°lido para este dataset
n_events = 0

# Solo se verifica si STI014 est√° en los canales
if 'STI014' in raw.ch_names:
    try:
        events = mne.find_events(raw, stim_channel='STI014', verbose=False)
        n_events = events.shape[0]
        events_ok = n_events > 0
        print(f"‚úÖ Canal de eventos detectado. N√∫mero de eventos: {n_events}")
    except Exception as e:
        print(f"‚ö†Ô∏è Canal STI014 ilegible: {e}")
        events_ok = False
else:
    print("‚ÑπÔ∏è Canal STI014 no est√° presente en este dataset. Se omite evaluaci√≥n de eventos.")

# Guardamos el resultado en un archivo CSV (`qc_event_check.csv`)
events_check_path = os.path.join(output_dir, "qc_event_check.csv")
pd.DataFrame([{
    "subject": subject_id,
    "events_ok": events_ok,
    "n_events": n_events if 'STI014' in raw.ch_names else "NA"
}]).to_csv(
    events_check_path,
    mode='a', index=False,
    header=not os.path.exists(events_check_path)
)

# Guardar etiquetas + valores num√©ricos en un √∫nico CSV (para comparaci√≥n pre/post)
n_bad_pre = len(bads_detected)
n_flat_pre = len(flats_detected)

df_psd = pd.DataFrame({
    "subject": [subject_id],
    "drift_present": [drift_present],
    "muscle_noise_present": [muscle_present],
    "clipping_pre": [has_clipping],
    "low_freq_power_pre": [power_drift],
    "high_freq_power_pre": [power_muscle],
    "psd_max": [np.max(psd_mean)],
    "psd_median": [np.median(psd_mean)],
    "n_bad_channels_pre": [n_bad_pre],
    "n_flat_channels_pre": [n_flat_pre]
})


df_psd.to_csv(
    os.path.join(output_dir, "qc_psd_summary.csv"),
    mode='a', index=False,
    header=not os.path.exists(os.path.join(output_dir, "qc_psd_summary.csv"))
)
print("‚úÖ PSD cuantitativo y artefactos guardados.")


# ========================== FASE 7: EXPORTAR INFORMES Y CLASIFICACI√ìN FINAL ==========================
# En esta fase se consolidan los resultados del QC en archivos separados para:
# - Resumen binario por sujeto
# - Flag de validez para preprocesamiento
# - Etiqueta de calidad t√©cnica global (3 niveles)
# Todas las decisiones se basan en m√©tricas cuantitativas reales obtenidas por compute_psd() o se√±ales crudas.

# --- 1. Resumen binario del QC por sujeto ---
# Incluye presencia de artefactos, clipping, canales malos y eventos
qc_summary = pd.DataFrame([{
    "subject": subject_id,
    "muscle_noise_>50Hz": muscle_present,        # Energ√≠a excesiva en >50 Hz (ruido EMG t√≠pico en tensi√≥n muscular)
    "low_freq_drift_<1.5Hz": drift_present,      # Potencia excesiva en <1.5 Hz, considerado drift t√©cnico o desacoplamiento
    "clipping_detected": has_clipping,           # Se√±al bruta con valores extremos (>5e-11 T) ‚Üí posible saturaci√≥n
    "n_bad_channels": n_bad_pre,                 # Canales ruidosos detectados por Maxwell filtering
    "stim_channel_present": events_ok if 'STI014' in raw.ch_names else "NA",           # Presencia del canal STI014 (evento codificado)
    "n_events": n_events if 'STI014' in raw.ch_names else "NA"
                          # N√∫mero total de eventos detectados
}])

qc_summary_path = os.path.join(output_dir, "qc_post_binary_summary.csv")

# Escritura robusta: elimina duplicados si ya existe una fila para este sujeto
if os.path.exists(qc_summary_path):
    df_old = pd.read_csv(qc_summary_path)
    df_old = df_old[df_old["subject"].astype(str).str.strip().str.lower() != subject_id.strip().lower()]
else:
    df_old = pd.DataFrame()

# Guardamos el resumen actualizado
df_final = pd.concat([df_old, qc_summary], ignore_index=True)
df_final.to_csv(qc_summary_path, index=False)

# --- 2. Flag de validez para preprocesamiento ---
# Se considera que el sujeto NO est√° listo para preprocesamiento si:
# - hay interferencia 60 Hz
# - hay ruido muscular
# - hay drift t√©cnico (<1.5 Hz)
# - hay clipping
# - hay m√°s de 3 canales ruidosos
#
# Justificaci√≥n:
# Estos artefactos indican que la se√±al puede estar severamente contaminada.
# M√°s de 3 canales malos sugiere que el sensor estaba mal colocado o mal calibrado.
qc_ready = (
    not has_clipping and
    n_bad_pre <= 3
)


# Guardamos el flag
pd.DataFrame([{
    "subject": subject_id,
    "qc_ready_for_preprocessing": qc_ready
}]).to_csv(
    os.path.join(output_dir, "qc_ready_flag.csv"),
    mode='a', index=False,
    header=not os.path.exists(os.path.join(output_dir, "qc_ready_flag.csv"))
)

# --- 3. Etiqueta de calidad t√©cnica (3 niveles) ---
# Clasificaci√≥n visual r√°pida seg√∫n n√∫mero de banderas activadas:
# - üî¥ severo: 3 o m√°s problemas detectados (alta probabilidad de datos no utilizables)
# - üü° moderado: exactamente 2 problemas (precauci√≥n recomendada)
# - üü¢ aceptable: 0 o 1 problema (apto para an√°lisis)
#
# Justificaci√≥n cl√≠nica:
# El umbral de ‚â•3 indicadores permite detectar sujetos con m√∫ltiples contaminaciones simult√°neas.
# Un solo artefacto no invalida el an√°lisis, pero m√∫ltiples s√≠ comprometen la validez.

summary_flags = sum([
    muscle_present,
    drift_present,
    has_clipping,
    n_bad_pre > 3
])

qc_quality_label = (
    "üî¥ severo" if summary_flags >= 3 else
    "üü° moderado" if summary_flags == 2 else
    "üü¢ aceptable"
)

# Guardamos la etiqueta de calidad t√©cnica
pd.DataFrame([{
    "subject": subject_id,
    "qc_tech_label": qc_quality_label
}]).to_csv(
    os.path.join(output_dir, "qc_quality_label.csv"),
    mode='a', index=False,
    header=not os.path.exists(os.path.join(output_dir, "qc_quality_label.csv"))
)


# ========================== FASE 8: INTERPRETACI√ìN Y LOG EXPLICATIVO ==========================
# Esta fase construye una interpretaci√≥n textual del QC para cada sujeto.
# Resume los hallazgos de forma comprensible, √∫til tanto para informes como para revisi√≥n manual o GUI.

interpretation = []  # Lista de anomal√≠as detectadas

if muscle_present:
    interpretation.append("ruido muscular >50‚ÄØHz")
if drift_present:
    interpretation.append("drift <1.5‚ÄØHz")
if has_clipping:
    interpretation.append("posible clipping o saturaci√≥n")
if n_bad_pre > 3:
    interpretation.append(f"m√°s de 3 canales ruidosos ({n_bad_pre})")
if 'STI014' in raw.ch_names and not events_ok:
          interpretation.append("‚ö†Ô∏è canal STI014 ausente o sin eventos")
if not interpretation:
    interpretation.append("‚úîÔ∏è sin anomal√≠as relevantes")  # Si no hay anomal√≠as, se indica expl√≠citamente

# Convertimos la lista en una cadena legible separada por +
interpretation_str = " + ".join(interpretation)

# Mostramos por pantalla un resumen del QC, incluyendo la etiqueta global de calidad
print(f"üìä QC autom√°tico para {subject_id}: {interpretation_str} | Calidad: {qc_quality_label} | Preprocesar: {qc_ready}")

# Guardamos esta interpretaci√≥n para que pueda consultarse desde el pipeline o informes
pd.DataFrame([{
    "subject": subject_id,
    "qc_interpretation": interpretation_str
}]).to_csv(
    os.path.join(output_dir, "qc_interpretation.csv"),
    mode='a', index=False,
    header=not os.path.exists(os.path.join(output_dir, "qc_interpretation.csv"))
)


# ========================== FINALIZACI√ìN ==========================
# Indicamos por pantalla que el QC ha finalizado correctamente para este sujeto.
print(f"‚úÖ QC completado para: {subject_id}")

