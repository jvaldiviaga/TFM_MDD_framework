#!/usr/bin/env Rscript
# ==========================================================
# Script: preprocessing_microarray.R
# Objetivo: Preprocesamiento adaptativo de microarrays Affymetrix
# Ejecuta QC t√©cnico, aplica normalizaci√≥n autom√°tica (rma o vsn), detecta efecto batch,
# genera visualizaciones y reportes t√©cnicos.
# Uso: Se llama desde preprocessing_master
# ==========================================================

# ========================== Script de Preprocesamiento Microarrays ==========================
# Descripci√≥n: Este script realiza el preprocesamiento adaptativo de datos de microarrays Affymetrix.
# Incluye: QC t√©cnico, decisi√≥n autom√°tica de normalizaci√≥n (rma vs vsn), correcci√≥n por batch (ComBat),
# visualizaciones adaptativas, e informes interpretativos.

# FUTURO: Este script asume entrada en formato Affymetrix (.CEL). No detecta otros formatos como Illumina o Agilent.
# Motivo: extender el framework a m√°s plataformas mejorar√° su aplicabilidad en otros contextos cl√≠nicos o estudios.

# NOTA: No se modulariza todo en funciones porque este script es espec√≠fico para microarrays Affymetrix.
# La arquitectura del framework se basa en tener scripts independientes por tipo de √≥mica,
# llamados desde preprocessing_master.R en funci√≥n del tipo de datos.
# Esto favorece la escalabilidad y evita cargar con funciones irrelevantes en flujos distintos (RNA-seq, metilaci√≥n, etc.)

# FORTALEZAS Y JUSTIFICACI√ìN DEL FLUJO:
# - Realiza preprocesamiento t√©cnico adaptativo de microarrays Affymetrix (.CEL) con l√≥gica condicional robusta.
# - Eval√∫a m√©tricas t√©cnicas clave (SD, carga, PCA, heatmap) para decidir entre `rma()` y `vsn()`.
# - Aplica correcci√≥n por efecto batch con `ComBat()` si detecta separaci√≥n significativa entre lotes.
# - Integra generaci√≥n de visualizaciones (boxplot, PCA, heatmap) y reportes autom√°ticos interpretables.
# - Detecta autom√°ticamente variables cl√≠nicas relevantes (`diagnosis`, `group`, etc.) sin necesidad de renombrarlas.
# - Optimizado para funcionar tanto de forma aut√≥noma como desde `preprocessing_master.R`.
# - Compatible con datasets grandes (‚â•100 muestras) mediante control de visualizaci√≥n adaptativo.
# - Genera archivos RDS, logs y reportes listos para an√°lisis diferencial o modelado posterior.

# =============================================================================================

# 1. Cargar librer√≠as necesarias
suppressPackageStartupMessages({
  library(affy)                # Lectura y manejo de archivos .CEL
  library(Biobase)             # Infraestructura ExpressionSet
  library(limma)               # Herramientas para an√°lisis lineal y normalizaci√≥n
  library(vsn)                 # Normalizaci√≥n por variancia estabilizada (VSN)
  library(arrayQualityMetrics) # QC avanzado interactivo
  library(pheatmap)           # Visualizaci√≥n de heatmaps
  library(sva)                # ComBat para correcci√≥n de efecto batch
})

# 2. Determinar ruta de entrada
args <- commandArgs(trailingOnly = TRUE)

# Si se pasa argumento por consola, lo usamos
if (length(args) > 0) {
  input_dir <- args[1]
  
  # Si no, buscamos si ya existe en el entorno global (usado desde master)
} else if (exists("input_dir", envir = .GlobalEnv)) {
  input_dir <- get("input_dir", envir = .GlobalEnv)
  
  # Si no hay forma de determinar la ruta, detenemos el script
} else stop("‚ùå No se ha proporcionado input_dir.")

# Extraemos el ID del dataset desde la ruta
dataset_id <- basename(input_dir)

# Definimos carpetas de resultados
results_dir <- file.path("~/TFM_MDD/results", dataset_id)
qc_dir <- file.path(results_dir, "qc_raw")

# Creamos las carpetas si no existen
dir.create(results_dir, recursive = TRUE, showWarnings = FALSE)
dir.create(qc_dir, recursive = TRUE, showWarnings = FALSE)
cat("üì• Iniciando preprocesamiento para:", dataset_id, "\n")

cat("üîç Leyendo archivos .CEL...\n")

# Extraemos la lista de archivos .CEL presentes en el directorio de entrada
cel_files <- list.files(input_dir, pattern = "\\.CEL$", full.names = TRUE, recursive = TRUE)
if (length(cel_files) == 0) stop("‚ùå No se encontraron archivos .CEL.")

# 3. Leer archivos .CEL (microarrays crudos)
# Cargamos los archivos .CEL utilizando la funci√≥n ReadAffy() del paquete 'affy',
# lo que genera un objeto AffyBatch con todos los datos crudos de microarrays Affymetrix.
raw_data <- ReadAffy(filenames = cel_files)

# Confirmaci√≥n por consola de que la lectura fue exitosa
cat("‚úÖ Archivos .CEL le√≠dos.\n")

# Extraemos la matriz de intensidades crudas a partir del objeto AffyBatch
exprs_mat <- exprs(raw_data)

# 4. QC preliminar (log2, NA, baja se√±al)
# Evaluamos si es necesario aplicar log2 seg√∫n la dispersi√≥n de los cuantiles (IQR)
# Si la mediana es muy alta o hay mucha diferencia entre Q1 y Q3, se asume que no est√° en escala log
qx <- quantile(exprs_mat, c(0.25, 0.75), na.rm = TRUE)
log_transform <- (qx[2] > 100) || ((qx[2] - qx[1]) > 50)

# Si detectamos que est√° en escala lineal, aplicamos log2 + 1 solo para an√°lisis QC (sin afectar normalizaci√≥n posterior)
exprs_raw <- if (log_transform) log2(exprs_mat + 1) else exprs_mat

# Mostramos por consola si se aplic√≥ log2 o no
cat(if (log_transform) "üîÅ Se aplic√≥ log2 para QC.\n" else "‚ÑπÔ∏è No se aplic√≥ log2.\n")

# Eliminamos genes (filas) que contengan valores NA en alguna muestra
na_rows <- which(rowSums(is.na(exprs_raw)) > 0)
if (length(na_rows) > 0) exprs_raw <- exprs_raw[-na_rows, ]

# Calculamos la intensidad media por gen y filtramos aquellos con se√±al muy baja
# Eliminamos los genes con intensidad media menor al percentil 20%
mean_intensity <- rowMeans(exprs_raw)
threshold <- quantile(mean_intensity, 0.2)
exprs_raw <- exprs_raw[mean_intensity > threshold, ]

# =============================================================================================
# FUTURO: Guardar matriz de expresi√≥n cruda filtrada antes de aplicar normalizaci√≥n
# Motivo: permite reutilizar estos datos para modelos predictivos u otras exploraciones sin repetir QC.
# Mejora la eficiencia computacional y la trazabilidad de decisiones t√©cnicas.
# saveRDS(exprs_raw, file.path(results_dir, "exprs_filtered.rds"))
# =============================================================================================

# 5. Visualizaciones b√°sicas
# Boxplot de intensidades crudas despu√©s del log2 (si se aplic√≥) y filtrado
# Permite evaluar la homogeneidad de la distribuci√≥n entre muestras
png(file.path(qc_dir, "boxplot_raw.png"), width = 1400)
boxplot(exprs_raw, las = 2, main = "Boxplot intensidades crudas")
dev.off()

# Histograma de todas las intensidades crudas tras preprocesamiento inicial
# √ötil para visualizar la distribuci√≥n global y detectar sesgos de intensidad
png(file.path(qc_dir, "histograma_intensidades.png"), width = 1000)
hist(as.numeric(exprs_raw), breaks = 100, col = "gray", main = "Histograma intensidades")
dev.off()

# 6. PCA y heatmap (si hay metadatos)
# Buscamos el archivo de metadatos cl√≠nicos correspondiente al dataset
meta_path <- list.files(input_dir, pattern = paste0("^", dataset_id, "_metadata\\.csv$"), full.names = TRUE)
has_meta <- length(meta_path) > 0

# Inicializamos variables que se usar√°n si hay metadatos
group_colors <- NULL           # Colores para los grupos en los plots
group_labels <- NULL           # Etiquetas de grupo (diagn√≥stico)
diagnosis_col <- NULL          # Nombre de la columna con la variable de diagn√≥stico
subset_cols <- NULL            # Columnas (muestras) seleccionadas para visualizaci√≥n balanceada

if (has_meta) {
  # Cargamos los metadatos conservando los nombres originales de columnas (ej. 'disease status:ch1')
  meta <- read.csv(meta_path[1], check.names = FALSE)  # ‚Üê Para conservar nombres con ":" intactos
  
  # Extraemos los identificadores GSM desde las columnas de expresi√≥n
  gsm_ids <- gsub("^([^_]+).*", "\\1", colnames(exprs_raw))
  colnames(exprs_raw) <- gsm_ids
  
  # Detecci√≥n autom√°tica de la columna de ID de muestra
  if ("geo_accession" %in% names(meta)) {
    meta_id_col <- "geo_accession"
  } else {
    # Buscamos columnas candidatas que puedan contener los IDs de muestra
    id_candidates <- grep("geo_accession|gsm|sample|id", names(meta), ignore.case = TRUE, value = TRUE)
    for (id_col in id_candidates) {
      if (any(meta[[id_col]] %in% colnames(exprs_raw))) {
        meta_id_col <- id_col
        break
      }
    }
    if (!exists("meta_id_col")) stop("‚ùå No se pudo detectar la columna de IDs en los metadatos.")
  }
  
  # Detecci√≥n autom√°tica de la variable cl√≠nica de diagn√≥stico
  diag_candidates <- grep("group|diagnosis|condition", names(meta), ignore.case = TRUE, value = TRUE)
  for (dc in diag_candidates) {
    if (length(unique(meta[[dc]])) >= 2) {
      diagnosis_col <- dc
      break
    }
  }
  
  # Si no se encontr√≥ en columnas est√°ndar, buscamos dentro de characteristics_ch1
  if (is.null(diagnosis_col)) {
    charac_cols <- grep("characteristics_ch1", names(meta), value = TRUE)
    for (col in charac_cols) {
      if (any(grepl("disease status", meta[[col]], ignore.case = TRUE))) {
        # Extraemos solo la parte del diagn√≥stico de la cadena
        meta[[col]] <- gsub(".*disease status:\\s*", "", meta[[col]])
        diagnosis_col <- col
        break
      }
    }
  }
  
  # =============================================================================================
  # FUTURO: A√±adir al informe balance de clases (MDD, Control) y sugerencia de m√©trica (AUC, F1)
  # Motivo: la mayor√≠a de m√©tricas est√°ndar como Accuracy pueden resultar enga√±osas si las clases est√°n desbalanceadas.
  # Por ejemplo, un modelo que predice siempre "Control" en un dataset con 80% de controles tendr√° 80% de accuracy pero ser√° in√∫til.
  # Soluci√≥n:
  # - Contar el n√∫mero de muestras por grupo tras detectar diagnosis_col y group_labels.
  # - Calcular el ratio entre clases (ej. n_mayor / n_menor).
  # - Si ratio > 1.5, imprimir una advertencia y sugerir usar AUC o F1-score en lugar de Accuracy.
  # - Esta decisi√≥n se puede guardar en el informe `qc_interpretacion.txt` o en un log global para el pipeline.
  # Justifica autom√°ticamente la m√©trica usada en la parte de DEG o modelos predictivos.
  # =============================================================================================
  
  
  # Si encontramos una columna de diagn√≥stico v√°lida, construimos los grupos
  if (!is.null(diagnosis_col) && !is.null(meta_id_col)) {
    diagnosis_vals <- meta[[diagnosis_col]]
    
    # Solo procedemos si hay al menos 2 grupos distintos
    if (length(unique(na.omit(diagnosis_vals))) >= 2) {
      g1 <- meta[meta[[diagnosis_col]] == unique(na.omit(diagnosis_vals))[1], meta_id_col]
      g2 <- meta[meta[[diagnosis_col]] == unique(na.omit(diagnosis_vals))[2], meta_id_col]
      
      # Intersectamos con las columnas reales del dataset (por si hay muestras no coincidentes)
      g1 <- intersect(g1, colnames(exprs_raw)); g2 <- intersect(g2, colnames(exprs_raw))
      
      # Seleccionamos 30 muestras por grupo de forma aleatoria pero reproducible
      n_select <- min(30, length(g1), length(g2))
      if (n_select >= 2) {
        set.seed(42)
        subset_cols <- c(sample(g1, n_select), sample(g2, n_select))
        exprs_subset <- exprs_raw[, subset_cols, drop = FALSE]
        meta <- meta[match(subset_cols, meta[[meta_id_col]]), ]
        group_labels <- as.factor(meta[[diagnosis_col]])
        group_colors <- as.numeric(group_labels)
      }
    }
  }
}

# Si no se detectaron metadatos cl√≠nicos v√°lidos, seleccionamos un subconjunto general
if (is.null(subset_cols)) {
  subset_cols <- head(colnames(exprs_raw), min(60, ncol(exprs_raw)))
  exprs_subset <- exprs_raw[, subset_cols, drop = FALSE]
}

# =============================================================================================
# FUTURO: Controlar las visualizaciones (PCA, heatmap, AQM) si el n√∫mero de muestras > 100
# Motivo: en sistemas con hardware limitado (como WSL2), realizar PCA o heatmap con muchas muestras (>100)
# puede agotar la RAM o hacer que el proceso se caiga (Killed).
# Soluci√≥n:
# - Implementar un flag de entrada al script como --skip_visuals o --limit_plot_n=60
# - O bien a√±adir un condicional autom√°tico que reduzca el n√∫mero de muestras para visualizaci√≥n:
#     - Si n_muestras > 100, seleccionar autom√°ticamente 30 por grupo cl√≠nico (como ya se hace)
#     - O simplemente evitar las visualizaciones para evitar errores
# Esto permite mantener el QC sin comprometer la estabilidad del script.
# =============================================================================================



# --- PCA ---
pca_done <- FALSE  # Indicador para registrar si el PCA se realiz√≥ correctamente

tryCatch({
  # Solo realizamos PCA si hay al menos 2 muestras y 2 genes con varianza no nula
  if (ncol(exprs_subset) >= 2 && nrow(exprs_subset) >= 2 && all(apply(exprs_subset, 1, var) != 0)) {
    pca <- prcomp(t(exprs_subset), scale. = TRUE)  # Transponemos para que las muestras sean filas
    
    # Guardamos gr√°fico de PCA coloreado por grupo cl√≠nico (si existe)
    png(file.path(qc_dir, "pca_subset_colored.png"), width = 1000)
    if (!is.null(group_colors) && length(unique(group_labels)) > 0) {
      plot(pca$x[, 1:2], col = group_colors, pch = 19,
           main = "PCA (grupos balanceados)", xlab = "PC1", ylab = "PC2")
      legend("topright", legend = levels(group_labels),
             col = 1:length(levels(group_labels)), pch = 19)
    } else {
      plot(pca$x[, 1:2], col = "blue", pch = 19,
           main = "PCA (sin metadatos)", xlab = "PC1", ylab = "PC2")
    }
    dev.off(); pca_done <- TRUE
  } else {
    stop("‚ùå Dataset insuficiente o con columnas constantes.")
  }
}, error = function(e) cat("‚ö†Ô∏è PCA fall√≥:", e$message, "\n"))

# --- Heatmap ---
heatmap_done <- FALSE  # Indicador para registrar si el heatmap se gener√≥ correctamente

tryCatch({
  if (ncol(exprs_subset) >= 2) {
    # Calculamos distancias entre muestras y la matriz correspondiente
    dists <- dist(t(exprs_subset))
    dist_mat <- as.matrix(dists)
    
    # Creamos anotaciones para las columnas si hay metadatos disponibles
    annotation_col <- NULL
    if (!is.null(group_labels)) {
      annotation_col <- data.frame(Grupo = group_labels)
      rownames(annotation_col) <- colnames(exprs_subset)
    }
    
    # Generamos el heatmap y lo guardamos
    png(file.path(qc_dir, "heatmap_subset.png"), width = 1000)
    pheatmap(dist_mat,
             main = "Heatmap (subset)",
             labels_col = FALSE,
             annotation_col = annotation_col,
             color = colorRampPalette(c("navy", "white", "firebrick3"))(100))
    dev.off()
    heatmap_done <- TRUE
  } else stop("‚ùå Muy pocas muestras para heatmap.")
}, error = function(e) cat("‚ö†Ô∏è Heatmap fall√≥:", e$message, "\n"))

# =============================================================================================
# FUTURO: Guardar en un archivo las columnas detectadas autom√°ticamente como diagnosis, ID o batch
# Motivo: facilita la auditor√≠a y documentaci√≥n del flujo automatizado.
# Especialmente √∫til si se quiere revisar qu√© columnas fueron usadas en cada ejecuci√≥n.
# writeLines(..., file.path(qc_dir, "columnas_detectadas.txt"))
# =============================================================================================

# 7. M√©tricas y gr√°ficos
# Carga total: suma de intensidades por muestra
carga <- colSums(exprs_raw)

# SD por muestra: eval√∫a la dispersi√≥n de se√±ales
sd_vals <- apply(exprs_raw, 2, sd)

# Guardamos m√©tricas num√©ricas en CSV
write.csv(carga, file.path(qc_dir, "carga_total.csv"))
write.csv(sd_vals, file.path(qc_dir, "sd_por_muestra.csv"))

# Calculamos rango de SD y ratio de carga entre muestras (para el diagn√≥stico posterior)
sd_range <- max(sd_vals) - min(sd_vals)
carga_ratio <- max(carga) / min(carga)

# Gr√°fico de barras: carga total por muestra
png(file.path(qc_dir, "carga_total.png"), width = 1000)
barplot(carga, las = 2, col = "darkblue", main = "Carga total por muestra", ylab = "Suma intensidades")
dev.off()

# Gr√°fico de barras: desviaci√≥n est√°ndar por muestra
png(file.path(qc_dir, "sd_por_muestra.png"), width = 1000)
barplot(sd_vals, las = 2, col = "darkred", main = "SD por muestra", ylab = "Desviaci√≥n est√°ndar")
dev.off()

# --- Interpretaci√≥n autom√°tica del QC previo a normalizaci√≥n ---

interpretacion <- c()          # Vector que almacenar√° los mensajes interpretativos
suggested_method <- "rma()"    # Valor por defecto (asume buena calidad t√©cnica)

# Evaluamos la SD: si es alta o muy variable ‚Üí sospechamos heterogeneidad t√©cnica
# Valores por encima de 1.4 o con un rango superior a 0.8 indican heterogeneidad t√©cnica significativa.
# Estos umbrales se basan en el rango t√≠pico esperado tras log2 para microarrays Affymetrix,
# donde una SD esperada suele estar entre 0.3 y 1.0. Valores mayores pueden indicar ruido t√©cnico,
# mala calidad o necesidad de una normalizaci√≥n m√°s robusta como vsn().
if (max(sd_vals) > 1.4 || sd_range > 0.8) {
  interpretacion <- c(interpretacion, "‚ö†Ô∏è SD alta o dispersi√≥n amplia ‚Üí posible ruido t√©cnico o muestras heterog√©neas.")
  suggested_method <- "vsn()"
} else {
  interpretacion <- c(interpretacion, "‚úÖ SD en rango esperado para datos log2.")
}

# Evaluamos la carga total por muestra (suma de intensidades): si hay gran disparidad ‚Üí sospecha de batch o muestras mal procesadas
# Si el cociente entre la muestra con mayor carga y la de menor carga supera 3,
# consideramos que puede haber un efecto t√©cnico (batch, calidad desigual).
# Este umbral est√° basado en experiencias pr√°cticas previas y en las recomendaciones
# para microarrays normalizados, donde idealmente la carga debe ser homog√©nea.
if (carga_ratio > 3) {
  interpretacion <- c(interpretacion, "‚ö†Ô∏è Carga total muy desigual ‚Üí posible efecto batch o calidad de muestra variable.")
  suggested_method <- "vsn()"
} else {
  interpretacion <- c(interpretacion, "‚úÖ Carga total homog√©nea entre muestras.")
}

# Evaluamos el resultado del PCA si se ha podido ejecutar y hay grupos cl√≠nicos detectados
if (pca_done && !is.null(group_labels)) {
  
  # Medimos la separaci√≥n entre los grupos en PC1 (media de cada grupo)
  pca_sep <- abs(mean(pca$x[group_labels == levels(group_labels)[1], 1]) -
                   mean(pca$x[group_labels == levels(group_labels)[2], 1]))
  
  # Si la distancia entre grupos es amplia, interpretamos como separaci√≥n clara
  # Evaluamos si existe separaci√≥n clara entre los grupos cl√≠nicos en PC1:
  # Calculamos la diferencia entre las medias de los grupos en PC1 (pca_sep).
  # Si esa distancia supera 2 unidades (en datos centrados y escalados), se considera
  # que hay una separaci√≥n significativa a nivel visual y t√©cnico.
  # Este umbral se basa en observaci√≥n emp√≠rica: en PCA con scale=TRUE, una distancia >2
  # indica agrupamientos visuales consistentes. No es un test estad√≠stico formal, pero sirve
  # como orientaci√≥n automatizada para sugerir si la se√±al biol√≥gica es clara o no.
  if (pca_sep > 2) {
    interpretacion <- c(interpretacion, "‚úÖ El PCA muestra una separaci√≥n clara entre grupos cl√≠nicos.")
  } else {
    interpretacion <- c(interpretacion, "‚ö†Ô∏è PCA sin separaci√≥n clara ‚Üí se√±al biol√≥gica d√©bil o efecto t√©cnico dominante.")
    suggested_method <- "vsn()"
  }
} else {
  interpretacion <- c(interpretacion, "‚ö†Ô∏è PCA no realizado o sin metadatos cl√≠nicos.")
}

# Evaluamos el resultado del heatmap si se gener√≥ correctamente
# No se usa un umbral num√©rico, pero si no se observan bloques definidos,
# se considera que no hay patr√≥n claro. Esto refuerza la recomendaci√≥n de usar vsn().
if (heatmap_done && !is.null(group_labels)) {
  interpretacion <- c(interpretacion, "‚úÖ El heatmap refleja cierta agrupaci√≥n por grupo cl√≠nico.")
} else {
  interpretacion <- c(interpretacion, "‚ö†Ô∏è Heatmap sin patr√≥n de bloques definido.")
  suggested_method <- "vsn()"
}

# Componemos el texto final que se imprimir√° y se guardar√°
qc_auto_txt <- c(
  "==================== INTERPRETACI√ìN AUTOM√ÅTICA ====================",
  interpretacion,
  paste0("üéØ Sugerencia de normalizaci√≥n basada en QC: ", suggested_method),
  "==================================================================="
)

# Guardamos el resumen en un archivo .txt dentro del directorio de QC
writeLines(qc_auto_txt, file.path(qc_dir, "interpretacion_automatizada.txt"))

# Tambi√©n lo imprimimos en consola
cat(paste(qc_auto_txt, collapse = "\n"), "\n")

# =============================================================================================
# FUTURO: Reemplazar el umbral fijo PC1 > 2 por una evaluaci√≥n estad√≠stica (ANOVA o PERMANOVA)
# Motivo: aportar√≠a una justificaci√≥n estad√≠stica m√°s rigurosa para aplicar ComBat.
# Relevante si se plantea publicaci√≥n o generalizaci√≥n del framework.
# =============================================================================================


# 8. Evaluaci√≥n t√©cnica
cat("\n=================== RESUMEN DE CALIDAD T√âCNICA ===================\n")
cat("üìä SD por muestra (esperado log2: 0.3 ‚Äì 1.0): ", round(min(sd_vals),2), "-", round(max(sd_vals),2), "\n")
if (max(sd_vals) > 1.4) cat("‚ö†Ô∏è SD alta: posible dispersi√≥n t√©cnica.\n") else cat("‚úÖ SD dentro del rango aceptable.\n")
cat("üì¶ Carga total (esperado homog√©nea; ratio ideal < 3x): ", round(min(carga)), "-", round(max(carga)), "\n")
if (carga_ratio > 3) cat("‚ö†Ô∏è Carga desigual ‚Üí posible efecto batch.\n") else cat("‚úÖ Carga relativamente homog√©nea.\n")
cat("üìà PCA ejecutado: ", if (pca_done) "‚úÖ S√≠" else "‚ö†Ô∏è No", "\n")
cat("üå°Ô∏è Heatmap generado: ", if (heatmap_done) "‚úÖ S√≠" else "‚ö†Ô∏è No", "\n")
cat("üß™ Se aplic√≥ log2 para QC: ", if (log_transform) "‚úÖ S√≠" else "‚ÑπÔ∏è No", "\n")
cat("üíæ Genes eliminados por NA: ", length(na_rows), "\n")
cat("üîï Genes filtrados por baja se√±al (20%): ", sum(mean_intensity <= threshold), "\n")
cat("=================================================================\n\n")

# 9. Detecci√≥n y correcci√≥n de batch (pData o metadatos externos)
# Inicializamos variables para registrar si se detecta efecto batch
combat_applied <- FALSE
batch_info <- list(source = NA, column = NA, levels = NA)
batch_effect_detected <- FALSE

# Nos aseguramos de que los nombres de las muestras (GSM IDs) sean consistentes en todas las matrices
gsm_ids <- gsub("^([^_]+).*", "\\1", sampleNames(raw_data))
sampleNames(raw_data) <- gsm_ids
colnames(exprs_mat) <- gsm_ids
colnames(exprs_raw) <- gsm_ids

# --- PCA por batch para evaluar efecto visual ---
# Buscamos el archivo de metadatos cl√≠nicos
meta_path <- list.files(input_dir, pattern = paste0("^", dataset_id, "_metadata\\.csv$"), full.names = TRUE)

if (length(meta_path) > 0) {
  meta_ext <- read.csv(meta_path[1], check.names = FALSE)
  
  # Detectamos columna con IDs (geo_accession o similares)
  id_col <- grep("geo_accession|gsm|sample|id", names(meta_ext), ignore.case = TRUE, value = TRUE)[1]
  
  # Detectamos posible columna de batch (e.g., 'batch:ch1', 'slide', 'run'...)
  batch_col_meta <- if ("batch:ch1" %in% names(meta_ext)) {
    "batch:ch1"
  } else {
    posibles <- grep("batch|lote|slide|array|run|scan", names(meta_ext), ignore.case = TRUE, value = TRUE)
    posibles[1]
  }
  
  # Continuamos solo si hay batch e ID v√°lidos
  if (!is.null(batch_col_meta) && !is.na(id_col)) {
    rownames(meta_ext) <- meta_ext[[id_col]]
    shared <- intersect(colnames(exprs_raw), rownames(meta_ext))
    
    if (length(shared) >= 10) {
      # Subconjunto para PCA por batch
      exprs_batch_pca <- exprs_raw[, shared, drop = FALSE]
      meta_batch <- meta_ext[shared, , drop = FALSE]
      batch_vec <- factor(trimws(as.character(meta_batch[[batch_col_meta]])))
      names(batch_vec) <- colnames(exprs_batch_pca)
      
      # Seleccionamos 30 muestras por batch para evitar cuellos de botella de RAM
      if (length(unique(batch_vec)) >= 2) {
        subset_cols <- unlist(lapply(levels(batch_vec), function(b) {
          ids <- names(batch_vec[batch_vec == b])
          if (length(ids) > 30) sample(ids, 30) else ids
        }))
        exprs_pca <- exprs_batch_pca[, subset_cols, drop = FALSE]
        pca_batch <- prcomp(t(exprs_pca), scale. = TRUE)
        batch_sub <- batch_vec[subset_cols]
        
        # Visualizamos el PCA coloreado por batches
        png(file.path(qc_dir, "pca_by_batch.png"), width = 1000)
        plot(pca_batch$x[, 1:2], col = as.numeric(batch_sub), pch = 19,
             main = "PCA por batch (subset)", xlab = "PC1", ylab = "PC2")
        legend("topright", legend = levels(batch_sub),
               col = 1:length(levels(batch_sub)), pch = 19)
        dev.off()
        
        # Detecci√≥n autom√°tica de efecto batch en PC1
        # Medimos la separaci√≥n entre batches en PC1
        pc1_means <- tapply(pca_batch$x[, 1], batch_sub, mean)
        if (length(unique(pc1_means)) >= 2) {
          diff_pc1 <- max(pc1_means) - min(pc1_means)
          
          # Umbral emp√≠rico: si diferencia > 2, asumimos efecto batch relevante
          # Evaluamos la separaci√≥n entre batches en la componente principal 1 (PC1).
          # Calculamos la diferencia entre las medias de PC1 por cada grupo de batch.
          #
          # üß† Justificaci√≥n del umbral:
          #   - En PCA con `scale. = TRUE`, las coordenadas est√°n en unidades de desviaci√≥n est√°ndar.
          #   - Una separaci√≥n > 2 indica que los batches difieren m√°s de 2 DE ‚Üí se√±al t√©cnica clara.
          #   - Este umbral es emp√≠rico y se basa en observaciones pr√°cticas en an√°lisis de microarrays.
          #   - Es r√°pido, reproducible y suficientemente robusto para automatizaci√≥n inicial.
          #
          # üîß FUTURO:
          #   - Para mayor rigor estad√≠stico, este umbral puede sustituirse por una prueba formal:
          #       1. ANOVA sobre PC1: `aov(pca_batch$x[,1] ~ batch_sub)`
          #       2. PERMANOVA (adonis): sobre la matriz de distancias, si se desea evaluar agrupamiento.
          #   - Estas alternativas permitir√≠an confirmar el efecto batch con significancia estad√≠stica,
          #     especialmente √∫til en estudios multic√©ntricos, con m√°s de 2 niveles o con tama√±os grandes.
          if (diff_pc1 > 2) {
            batch_effect_detected <- TRUE
            cat("‚úÖ Separaci√≥n clara entre batches en PCA: se aplicar√° ComBat.\n")
          } else {
            cat("‚ÑπÔ∏è No hay suficiente separaci√≥n entre batches en PCA. No se aplicar√° ComBat.\n")
          }
        }
      }
    }
  }
}

# Funci√≥n auxiliar que aplica ComBat y guarda el resultado como RDS
# ==========================================================
# Esta funci√≥n aplica la correcci√≥n por batch a una matriz de expresi√≥n normalizada,
# utilizando la librer√≠a sva::ComBat. Es robusta frente a errores y controla el uso de RAM.
# Tambi√©n guarda el resultado como archivo .rds para facilitar reproducibilidad.
# ==========================================================
apply_combat <- function(exprs_matrix, batch_vector, origen) {
  
  # Verificamos que el vector de batches coincida en longitud y nombres con las columnas de expresi√≥n
  if (length(batch_vector) != ncol(exprs_matrix) || !all(names(batch_vector) == colnames(exprs_matrix))) {
    stop("‚ùå batch_vector mal alineado con columnas de expresi√≥n.")
  }
  
  # Creamos el modelo de dise√±o para ComBat (intercepto solamente)
  mod <- model.matrix(~1, data = data.frame(batch = batch_vector))
  
  n_samples <- ncol(exprs_matrix)
  corrected <- NULL  # Inicializamos la variable para guardar el resultado corregido
  
  # Si el n√∫mero de muestras es muy alto (>250), evitamos usar par√°metros emp√≠ricos para ahorrar RAM
  force_mean_only <- n_samples > 250
  
  if (force_mean_only) {
    cat("‚ö†Ô∏è Demasiadas muestras (", n_samples, ") ‚Üí Usando mean.only = TRUE para evitar Killed.\n")
    
    # mean.only=TRUE aplica solo correcci√≥n de medias, menos intensiva en RAM
    corrected <- ComBat(dat = exprs_matrix, batch = batch_vector, mod = mod, mean.only = TRUE)
    
  } else {
    # Intentamos aplicar ComBat con prior emp√≠rico (mejor estimaci√≥n bayesiana)
    tryCatch({
      corrected <- ComBat(dat = exprs_matrix, batch = batch_vector, mod = mod, par.prior = TRUE)
      
    }, error = function(e1) {
      # Si falla, caemos en un modo de seguridad con mean.only=TRUE
      cat("‚ö†Ô∏è Error con par.prior=TRUE: ", e1$message, "\n")
      corrected <- ComBat(dat = exprs_matrix, batch = batch_vector, mod = mod, mean.only = TRUE)
    })
  }
  
  # Si por alg√∫n motivo no se pudo aplicar ComBat, se lanza error cr√≠tico
  if (is.null(corrected)) {
    stop("‚ùå ComBat no pudo aplicarse correctamente.")
  }
  
  # Guardamos el resultado corregido como archivo RDS para trazabilidad
  saveRDS(corrected, file = file.path(results_dir, "normalized_expression_combat.rds"))
  
  # Mensaje de confirmaci√≥n
  cat("‚úîÔ∏è ComBat aplicado desde", origen, "\n")
  
  # Devolvemos la matriz corregida para continuar el flujo del pipeline
  return(corrected)
}



# 10. Normalizaci√≥n adaptativa basada en evaluaci√≥n t√©cnica previa
# Evaluamos si hay dispersi√≥n t√©cnica o problemas de calidad que desaconsejen el uso de rma().
# Si se detecta alguna de estas condiciones, se prefiere vsn() (m√°s robusta pero m√°s lenta):
# 1. SD por muestra muy elevada (>1.4) o rango amplio (>0.8) ‚Üí indica muestras ruidosas.
# 2. Carga total muy desigual (ratio > 3) ‚Üí posible problema de escaneo o lote.
# 3. PCA o heatmap no pudieron generarse ‚Üí se√±al inconsistente o fallos de visualizaci√≥n.
alta_dispersion <- (max(sd_vals) > 1.4 || sd_range > 0.8 || carga_ratio > 3 || !pca_done || !heatmap_done)
criterio <- metodo <- NULL  # Inicializamos variables para registrar la decisi√≥n tomada

tryCatch({
  
  # Si hay alta dispersi√≥n ‚Üí aplicamos vsn() (normalizaci√≥n robusta)
  if (alta_dispersion) {
    eset <- expresso(raw_data, bg.correct = FALSE, normalize = FALSE,
                     pmcorrect.method = "pmonly", summary.method = "avgdiff")
    norm_data <- exprs(vsn2(exprs(eset)))
    metodo <- "vsn()"
    criterio <- "Dispersi√≥n global detectada"
    
    # Si no hay dispersi√≥n ‚Üí aplicamos rma() (r√°pida y apropiada)
  } else {
    norm_data <- exprs(rma(raw_data))
    metodo <- "rma()"
    criterio <- "Homogeneidad t√©cnica aceptable"
  }
}, error = function(e) {
  # En caso de error (por ejemplo, fallo en rma), aplicamos vsn() como fallback
  cat("‚ö†Ô∏è Normalizaci√≥n fallida: ", e$message, "\n")
  eset <- expresso(raw_data, bg.correct = FALSE, normalize = FALSE,
                   pmcorrect.method = "pmonly", summary.method = "avgdiff")
  norm_data <- exprs(vsn2(exprs(eset)))
  metodo <<- "vsn()"
  criterio <<- "Fallback tras fallo en rma()"
})

# Guardamos la matriz de expresi√≥n normalizada, independientemente del m√©todo
saveRDS(norm_data, file = file.path(results_dir, "normalized_expression.rds"))

# --- Aplicamos ComBat solo si previamente se detect√≥ efecto batch significativo ---
if (batch_effect_detected) {
  
  # Verificamos que las muestras del batch coincidan con las columnas normalizadas
  shared_cols <- intersect(colnames(norm_data), names(batch_vec))
  
  if (length(shared_cols) < ncol(norm_data)) {
    warning("‚ö†Ô∏è ComBat no se aplicar√° a todas las muestras. Verifica nombres de columnas.")
  }
  
  # Seleccionamos las columnas comunes para aplicar ComBat
  norm_data_shared <- norm_data[, shared_cols, drop = FALSE]
  
  # Guardamos la informaci√≥n de batch (para incluir en logs o informes)
  batch_info <- list(source = "metadata", column = batch_col_meta, levels = length(unique(batch_vec)))
  
  # Aplicamos ComBat sobre la matriz normalizada
  corrected <- apply_combat(norm_data_shared, batch_vec[shared_cols], "metadatos externos")
  
  # Actualizamos la matriz normalizada con la versi√≥n corregida
  norm_data <- corrected
  combat_applied <- TRUE
  
  # Guardamos la versi√≥n final corregida por batch
  saveRDS(norm_data, file = file.path(results_dir, "normalized_expression.rds"))
} else {
  cat("‚ÑπÔ∏è No se aplicar√° ComBat porque no se detect√≥ efecto batch significativo.\n")
}


# 11. Registro de decisiones de normalizaci√≥n y sesi√≥n R
# Mostramos por consola el m√©todo y el criterio t√©cnico que se ha aplicado
cat("üéØ M√©todo de normalizaci√≥n aplicado: ", metodo, "\n")
cat("üß† Justificaci√≥n t√©cnica: ", criterio, "\n")

# Guardamos el m√©todo elegido (rma vs vsn) y la raz√≥n en un archivo de texto plano
# Este archivo permite trazar qu√© decisi√≥n se tom√≥ para cada dataset en ejecuci√≥n en lote
writeLines(c(
  paste0("M√©todo de normalizaci√≥n: ", metodo),
  paste0("Justificaci√≥n: ", criterio)
), file.path(results_dir, "decision_normalizacion.txt"))

# Guardamos la informaci√≥n de la sesi√≥n R completa (versiones, paquetes cargados)
# Es esencial para reproducibilidad, sobre todo si cambia el entorno o se migra a otro equipo
writeLines(capture.output(sessionInfo()), file.path(results_dir, "session_info.txt"))

# Creamos un informe m√°s interpretativo y explicativo que resume las m√©tricas clave del QC
# Incluye SD, carga total, n√∫mero de genes retenidos, decisi√≥n de normalizaci√≥n y si se aplic√≥ ComBat
writeLines(c(
  "==================== INFORME QC ADAPTATIVO ====================",
  paste0("üîé Dataset: ", dataset_id),
  paste0("üß¨ Genes tras filtrado: ", nrow(exprs_raw)),
  paste0("üìä SD (min/max): ", round(min(sd_vals), 2), " / ", round(max(sd_vals), 2)),
  paste0("üì¶ Carga total: ", round(min(carga)), " / ", round(max(carga))),
  paste0("üéØ Normalizaci√≥n: ", metodo),
  paste0("üß† Criterio: ", criterio),
  if (combat_applied) "‚úîÔ∏è ComBat aplicado por batch detectado." else "‚ÑπÔ∏è No se aplic√≥ ComBat.",
  if (!is.null(group_labels)) paste0("üìò PCA coloreado por: ", diagnosis_col) else "‚ö†Ô∏è PCA sin metadatos cl√≠nicos.",
  "==============================================================="
), file.path(qc_dir, "qc_interpretacion.txt"))


# 12. Ejecuci√≥n de arrayQualityMetrics (solo si hay ‚â§ 100 muestras)
# Si hay pocas muestras, ejecutamos arrayQualityMetrics para generar un informe interactivo en HTML
# Este informe incluye m√∫ltiples gr√°ficas de diagn√≥stico (MA plots, boxplots, PCA, etc.)
# No se usa en datasets grandes porque puede consumir mucha RAM o colapsar en WSL2
if (ncol(exprs_raw) <= 100) {
  tryCatch({
    cat("üìä Ejecutando arrayQualityMetrics...\n")
    arrayQualityMetrics(expressionset = raw_data,
                        outdir = file.path(qc_dir, "arrayQualityMetrics"),
                        force = TRUE, do.logtransform = FALSE)
    cat("‚úÖ arrayQualityMetrics completado.\n")
  }, error = function(e) {
    cat("‚ö†Ô∏è arrayQualityMetrics fall√≥:", e$message, "\n")
  })
} else {
  
  # En datasets grandes, evitamos ejecutarlo por limitaciones de hardware
  cat("‚ÑπÔ∏è Demasiadas muestras para arrayQualityMetrics (omitido).\n")
}

# Mensaje final indicando que todo el flujo de preprocesamiento ha terminado correctamente
cat("‚úÖ Preprocesamiento completado y listo para el pipeline.\n")
